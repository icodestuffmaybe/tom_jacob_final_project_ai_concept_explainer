{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8s5j3XQ8mv9_"
   },
   "source": [
    "# AI Agents Capstone Project: Dynamic Blog Writer\n",
    "## Building a Multi-Agent System Step by Step\n",
    "\n",
    "**Course**: AI Explorers: Introduction to AI Agents  \n",
    "**Project Type**: Capstone - 5 Progressive Exercises  \n",
    "**Learning Objective**: Apply the ReAct framework and agentic workflows to build a complete multi-agent system\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 Course Concepts Review\n",
    "\n",
    "Before starting, let's review the key concepts from [Session 3 Notes](session_course_notes.html):\n",
    "\n",
    "### The Agent Formula\n",
    "**🧠 A Brain (LLM) + 🧰 A Set of Tools = 🤖 An AI Agent**\n",
    "\n",
    "### The ReAct Framework\n",
    "- **Thought**: The agent reasons about the problem\n",
    "- **Action**: The agent chooses and uses a tool\n",
    "- **Observation**: The agent receives results and continues the loop\n",
    "\n",
    "### Agentic Workflow Pattern: Evaluator-Optimizer\n",
    "One agent creates a draft, another agent critiques it, creating a loop of continuous improvement.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Project Overview\n",
    "\n",
    "You'll build a **Dynamic Blog Writer** that uses 5 specialized agents working together:\n",
    "\n",
    "1. **Persona Architect** 🎭 - Creates writer personas and search strategies\n",
    "2. **Research Analyst** 🔍 - Conducts web research and gathers information  \n",
    "3. **Content Synthesizer** ✍️ - Writes blog posts based on persona and research\n",
    "4. **Critic** 🔍 - Evaluates drafts against quality principles\n",
    "5. **Editor** ✏️ - Provides feedback and manages the iterative improvement process\n",
    "\n",
    "This demonstrates the **Evaluator-Optimizer** workflow pattern you learned about!\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Setup Instructions\n",
    "\n",
    "### Option 1: Google Colab (Recommended)\n",
    "1. **Open this notebook** in Google Colab\n",
    "2. **Add API Key Secret**:\n",
    "   - Click the 🔑 key icon in the left sidebar\n",
    "   - Add secret: `GEMINI_API_KEY`\n",
    "   - Get your key from: https://ai.google.dev/\n",
    "   - **Enable notebook access** for the secret\n",
    "3. **Run Setup**: Execute all setup cells in order\n",
    "4. **Start Coding**: Begin with Exercise 1\n",
    "\n",
    "### Option 2: Local Environment (VS Code, Cursor, etc.)\n",
    "1. **Clone/Download** this project to your local machine\n",
    "2. **Install Dependencies**:\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "3. **Set API Key** (choose one method):\n",
    "   - **Environment Variable**: `export GEMINI_API_KEY=your_key_here`\n",
    "   - **VS Code Settings**: Add to your workspace settings\n",
    "   - **Direct Input**: The notebook will prompt you for the key\n",
    "4. **Launch Jupyter**:\n",
    "   ```bash\n",
    "   jupyter notebook agent_capstone_exercises.ipynb\n",
    "   ```\n",
    "5. **Start Coding**: Execute setup cells and begin with Exercise 1\n",
    "\n",
    "### Troubleshooting\n",
    "- **API Key Issues**: Ensure your Gemini API key is valid and properly set\n",
    "- **Package Issues**: Run `pip install --upgrade -r requirements.txt`\n",
    "- **Import Errors**: Restart your kernel/runtime after installing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgso66-2mv-K"
   },
   "source": [
    "## Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19015,
     "status": "ok",
     "timestamp": 1756083147300,
     "user": {
      "displayName": "Jacob Zhang",
      "userId": "17792333630785635876"
     },
     "user_tz": 240
    },
    "id": "zGyJWKVymv-N",
    "outputId": "9115fce1-155b-4ace-ed18-b77dff53b4b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing google-generativeai...\n",
      "Requirement already satisfied: google-generativeai in ./.venv/lib/python3.12/site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in ./.venv/lib/python3.12/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in ./.venv/lib/python3.12/site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in ./.venv/lib/python3.12/site-packages (from google-generativeai) (2.179.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in ./.venv/lib/python3.12/site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.12/site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in ./.venv/lib/python3.12/site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.12/site-packages (from google-generativeai) (4.14.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./.venv/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.12/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in ./.venv/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in ./.venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./.venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in ./.venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./.venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./.venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in ./.venv/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: google-generativeai in ./.venv/lib/python3.12/site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in ./.venv/lib/python3.12/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in ./.venv/lib/python3.12/site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in ./.venv/lib/python3.12/site-packages (from google-generativeai) (2.179.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in ./.venv/lib/python3.12/site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.12/site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in ./.venv/lib/python3.12/site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.12/site-packages (from google-generativeai) (4.14.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./.venv/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.12/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in ./.venv/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in ./.venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./.venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in ./.venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./.venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./.venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in ./.venv/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Installing beautifulsoup4...\n",
      "Installing beautifulsoup4...\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.12/site-packages (4.13.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4) (4.14.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.12/site-packages (4.13.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4) (4.14.1)\n",
      "All packages installed successfully!\n",
      "All packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install required packages\n",
    "install_package('google-generativeai')\n",
    "install_package('beautifulsoup4')\n",
    "install_package('requests')\n",
    "\n",
    "print(\"All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5347,
     "status": "ok",
     "timestamp": 1756083152643,
     "user": {
      "displayName": "Jacob Zhang",
      "userId": "17792333630785635876"
     },
     "user_tz": 240
    },
    "id": "cJYsxoddmv-S",
    "outputId": "060ca922-bb82-4f86-c7fa-36d1765a50ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "import google.generativeai as genai\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1756083152988,
     "user": {
      "displayName": "Jacob Zhang",
      "userId": "17792333630785635876"
     },
     "user_tz": 240
    },
    "id": "A83ltnwomv-U",
    "outputId": "96d2c31b-fb3a-4bdd-a077-f2f30d7f118c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Gemini Pro 2.5 model initialized successfully!\n",
      "📝 Ready to start building your multi-agent system!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gemini_api_key = \"AIzaSyCsPwEbRfC_sWhat6OjhUqBQwJU07KmuPc\"# Configuration - API Key Setup\n",
    "'''\n",
    "try:\n",
    "    # Try Google Colab secrets first\n",
    "    from google.colab import userdata\n",
    "    gemini_api_key = userdata.get('GEMINI_API_KEY')\n",
    "    print(\"✅ Using Google Colab secrets\")\n",
    "except ImportError:\n",
    "    # Fallback for local Jupyter\n",
    "    gemini_api_key = os.environ.get('GEMINI_API_KEY')\n",
    "    if not gemini_api_key:\n",
    "        gemini_api_key = input(\"Enter your Gemini API key: \")\n",
    "    print(\"✅ Using local environment/input\")\n",
    "'''\n",
    "# Configure Gemini\n",
    "if not gemini_api_key:\n",
    "    raise ValueError(\"❌ GEMINI_API_KEY not found. Please add it to Colab secrets or environment variables.\")\n",
    "\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "model = genai.GenerativeModel('gemini-2.5-pro')\n",
    "\n",
    "print(\"🤖 Gemini Pro 2.5 model initialized successfully!\")\n",
    "print(\"📝 Ready to start building your multi-agent system!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b33JPlCPmv-W"
   },
   "source": [
    "## Data Classes and Quality Principles\n",
    "\n",
    "First, let's define the data structures and quality principles that our agents will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1756083153013,
     "user": {
      "displayName": "Jacob Zhang",
      "userId": "17792333630785635876"
     },
     "user_tz": 240
    },
    "id": "c1oteFHNmv-Z",
    "outputId": "4d8a9e5a-0deb-4af5-f207-5eff90b46e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Data classes defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Data classes for our multi-agent system\n",
    "@dataclass\n",
    "class PersonaResult:\n",
    "    persona_prompt: str\n",
    "    search_queries: List[str]\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    title: str\n",
    "    url: str\n",
    "    snippet: str\n",
    "\n",
    "@dataclass\n",
    "class ResearchResult:\n",
    "    content: str\n",
    "    source_count: int = 0\n",
    "\n",
    "@dataclass\n",
    "class BlogDraft:\n",
    "    content: str\n",
    "    version: int\n",
    "\n",
    "@dataclass\n",
    "class QualityReview:\n",
    "    is_approved: bool\n",
    "    feedback: str\n",
    "    issues_found: List[str]\n",
    "\n",
    "@dataclass\n",
    "class EditorReview:\n",
    "    is_approved: bool\n",
    "    comments: str\n",
    "\n",
    "print(\"📋 Data classes defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1756083153037,
     "user": {
      "displayName": "Jacob Zhang",
      "userId": "17792333630785635876"
     },
     "user_tz": 240
    },
    "id": "HZflDadlmv-c",
    "outputId": "e7555f86-273b-4145-b9df-e53b576e4033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Quality principles established:\n",
      "\n",
      "FUNDAMENTAL PRINCIPLES OF QUALITY WRITING:\n",
      "\n",
      "P1: Evidentiary Support\n",
      "All claims must be directly traceable to the provided research material.\n",
      "\n",
      "P2: Clarity and Conciseness\n",
      "Writing must be precise, unambiguous, and free of unnecessary jargon.\n",
      "\n",
      "P3: Engaging Narrative\n",
      "The post must feature a strong hook, a logical flow, and a memorable conclusion.\n",
      "\n",
      "P4: Structural Integrity\n",
      "The output must be well-organized with a clear title, introduction, body, and conclusion.\n",
      "\n",
      "P5: Intellectual Honesty\n",
      "Information must be represented accurately, even when adopting a specific persona.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quality Principles - The foundation of good writing\n",
    "QUALITY_PRINCIPLES = \"\"\"\n",
    "FUNDAMENTAL PRINCIPLES OF QUALITY WRITING:\n",
    "\n",
    "P1: Evidentiary Support\n",
    "All claims must be directly traceable to the provided research material.\n",
    "\n",
    "P2: Clarity and Conciseness\n",
    "Writing must be precise, unambiguous, and free of unnecessary jargon.\n",
    "\n",
    "P3: Engaging Narrative\n",
    "The post must feature a strong hook, a logical flow, and a memorable conclusion.\n",
    "\n",
    "P4: Structural Integrity\n",
    "The output must be well-organized with a clear title, introduction, body, and conclusion.\n",
    "\n",
    "P5: Intellectual Honesty\n",
    "Information must be represented accurately, even when adopting a specific persona.\n",
    "\"\"\"\n",
    "\n",
    "print(\"🎯 Quality principles established:\")\n",
    "print(QUALITY_PRINCIPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UioFMgzomv-f"
   },
   "source": [
    "## Utility Classes\n",
    "\n",
    "Let's set up some utility classes for web searching and file management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1756083153103,
     "user": {
      "displayName": "Jacob Zhang",
      "userId": "17792333630785635876"
     },
     "user_tz": 240
    },
    "id": "r2F0Ht1Omv-h",
    "outputId": "94924e56-5095-450e-d3ac-fa22f12baf0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Web searcher initialized (using free DuckDuckGo search)\n",
      "📂 File manager ready\n"
     ]
    }
   ],
   "source": [
    "class FreeWebSearcher:\n",
    "    \"\"\"Simple web search using DuckDuckGo (no API key required).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        })\n",
    "\n",
    "    def search(self, query: str, num_results: int = 5) -> List[SearchResult]:\n",
    "        \"\"\"Perform a free web search using DuckDuckGo.\"\"\"\n",
    "        try:\n",
    "            search_url = f\"https://html.duckduckgo.com/html/?q={quote_plus(query)}\"\n",
    "            response = self.session.get(search_url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            results = []\n",
    "\n",
    "            for result_div in soup.find_all('div', class_='result')[:num_results]:\n",
    "                try:\n",
    "                    title_elem = result_div.find('a', class_='result__a')\n",
    "                    snippet_elem = result_div.find('a', class_='result__snippet')\n",
    "\n",
    "                    if title_elem and snippet_elem:\n",
    "                        title = title_elem.get_text(strip=True)\n",
    "                        url = title_elem.get('href', '')\n",
    "                        snippet = snippet_elem.get_text(strip=True)\n",
    "\n",
    "                        if title and url and snippet:\n",
    "                            results.append(SearchResult(title=title, url=url, snippet=snippet))\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Search error: {e}\")\n",
    "            return []\n",
    "\n",
    "class FileManager:\n",
    "    \"\"\"Manages file operations for the blog writing project.\"\"\"\n",
    "\n",
    "    def __init__(self, topic: str):\n",
    "        self.topic = topic\n",
    "        self.date_str = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "        # Create simple folder name\n",
    "        topic_abbrev = re.sub(r'[^a-zA-Z0-9]', '_', topic.lower())[:20]\n",
    "        self.folder_name = f\"{self.date_str}_{topic_abbrev}\"\n",
    "        self.output_dir = Path(self.folder_name)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        print(f\"📁 Created output directory: {self.output_dir}\")\n",
    "\n",
    "    def save_file(self, content: str, filename: str) -> Path:\n",
    "        filepath = self.output_dir / filename\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        print(f\"💾 Saved: {filepath}\")\n",
    "        return filepath\n",
    "\n",
    "# Initialize web searcher\n",
    "web_searcher = FreeWebSearcher()\n",
    "print(\"🔍 Web searcher initialized (using free DuckDuckGo search)\")\n",
    "print(\"📂 File manager ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWGnq1I7mv-k"
   },
   "source": [
    "---\n",
    "\n",
    "# 🎯 Exercise 1: Persona Architect Agent\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand how to create specialized agent personas\n",
    "- Learn to generate targeted search queries\n",
    "- Practice JSON output formatting for agent communication\n",
    "\n",
    "## Background\n",
    "The **Persona Architect** is your first agent. Its job is to:\n",
    "1. Analyze the topic and style requirements\n",
    "2. Create a detailed writer persona\n",
    "3. Generate search queries for research\n",
    "\n",
    "This follows the **ReAct** pattern:\n",
    "- **Thought**: \"I need to create a persona suitable for this topic\"\n",
    "- **Action**: Generate persona and queries using the LLM\n",
    "- **Observation**: Return structured results for the next agent\n",
    "\n",
    "## Your Task\n",
    "Complete the `PersonaArchitect` class by implementing the `generate_persona_and_queries` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1756083489631,
     "user": {
      "displayName": "Jacob Zhang",
      "userId": "17792333630785635876"
     },
     "user_tz": 240
    },
    "id": "2O75FWeWmv-l",
    "outputId": "d842d445-58a4-410c-e124-241eea0aeb5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎭 PersonaArchitect class defined\n",
      "⚠️  TODO: Implement the generate_persona_and_queries method\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nresult_results = pa.generate_persona_and_queries(\\n        \"The History the domestication of chickens\",\\n        \"Professional, accessible tone for general audience\")\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "class PersonaArchitect:\n",
    "    \"\"\"Agent that creates writer personas and search strategies.\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def generate_persona_and_queries(self, topic: str, style_and_background: str) -> PersonaResult:\n",
    "        \"\"\"Generate a writer persona and search queries for the given topic.\n",
    "\n",
    "        Args: your persona is an instructive professor. you should write neatly, in understandable sentences.\n",
    "            topic: the history of the domestication of chickens\n",
    "            style_and_background: nerd with a wide range of facts of the history of chickens\n",
    "\n",
    "        Returns:\n",
    "            PersonaResult with persona_prompt and search_queries\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Create a prompt that will generate both a writer persona and search queries\n",
    "        # HINT: The persona should include writing style, expertise, and perspective\n",
    "        # HINT: Search queries should be diverse and targeted to find current information\n",
    "        # HINT: Return the result as JSON with \"persona_prompt\" and \"search_queries\" fields\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        # TODO:  your persona is an instructive professor. you should write neatly, in understandable sentences.\n",
    "            topic: the history of the domestication of chickens.\n",
    "            style_and_background: nerd with a wide range of facts of the history of chickens.\n",
    "            Be instructive, intelligent, and show all perspectives of the events. search up things related to the domestication of chickens.\n",
    "        # Remember to:\n",
    "        # 1. Ask for a detailed writer persona based on the topic and style\n",
    "        # 2. Ask for at least 3 search queries\n",
    "        # 3. Request JSON output format\n",
    "        # 4. Be specific about what makes a good persona (expertise, style, voice)\n",
    "\n",
    "        TOPIC: {topic}\n",
    "        STYLE_REQUIREMENTS: {style_and_background}\n",
    "\n",
    "        # create a blog about the history of the domestication of chickens\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Make the API call and parse the JSON response\n",
    "        # HINT: Use self.model.generate_content(prompt)\n",
    "        # HINT: Clean the response text and use json.loads()\n",
    "        # HINT: Handle potential JSON parsing errors\n",
    "\n",
    "        try:\n",
    "            # TODO: Generate content and parse JSON\n",
    "            response = self.model.generate_content(prompt)\n",
    "            response_text = response.text.strip()\n",
    "\n",
    "            # Try to extract JSON from the response\n",
    "            try:\n",
    "                # Find the first '{' and last '}' to extract JSON block\n",
    "                start = response_text.find('{')\n",
    "                end = response_text.rfind('}')\n",
    "                json_str = response_text[start:end+1]\n",
    "                data = json.loads(json_str)\n",
    "            except Exception as json_err:\n",
    "                print(f\"⚠️ JSON parsing error: {json_err}\")\n",
    "                raise\n",
    "\n",
    "            return PersonaResult(\n",
    "                persona_prompt=data.get(\"persona_prompt\", \"\"),\n",
    "                search_queries=data.get(\"search_queries\", [])\n",
    "            )\n",
    "\n",
    "            # TODO: Extract and clean the response text\n",
    "            response_text = \"\"  # Replace with cleaned response\n",
    "\n",
    "            # TODO: Parse JSON and create PersonaResult\n",
    "            data = {}  # Replace with parsed JSON\n",
    "\n",
    "            return PersonaResult(\n",
    "                persona_prompt=\"\",  # TODO: Extract from data\n",
    "                search_queries=[]   # TODO: Extract from data\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in PersonaArchitect: {e}\")\n",
    "            raise\n",
    "\n",
    "# Test your implementation\n",
    "print(\"🎭 PersonaArchitect class defined\")\n",
    "print(\"⚠️  TODO: Implement the generate_persona_and_queries method\")\n",
    "# Implementation guidance for generate_persona_and_queries:\n",
    "# 1. Build a prompt that instructs the model to output a JSON object with \"persona_prompt\" and \"search_queries\".\n",
    "# 2. Use self.model.generate_content(prompt) to get the response.\n",
    "# 3. Extract the JSON from the response text (sometimes models wrap JSON in markdown/code blocks).\n",
    "# 4. Parse the JSON and return a PersonaResult.\n",
    "\n",
    "# Example implementation:\n",
    "\n",
    "def extract_json_block(text):\n",
    "    \"\"\"Extract JSON object from a string, even if wrapped in code block.\"\"\"\n",
    "    start = text.find('{')\n",
    "    end = text.rfind('}')\n",
    "    if start != -1 and end != -1:\n",
    "        return text[start:end+1]\n",
    "    raise ValueError(\"No JSON object found in response.\")\n",
    "\n",
    "class PersonaResult:\n",
    "    def __init__(self, persona_prompt: str, search_queries: List[str]):\n",
    "        self.persona_prompt = persona_prompt\n",
    "        self.search_queries = search_queries\n",
    "\n",
    "def generate_persona_and_queries(self, topic: str, style_and_background: str) -> PersonaResult:\n",
    "    prompt = (\n",
    "        f\"Create a detailed writer persona for the following blog topic and style requirements.\\n\"\n",
    "        f\"Topic: {topic}\\n\"\n",
    "        f\"Style and background: {style_and_background}\\n\"\n",
    "        f\"Return a JSON object with two fields:\\n\"\n",
    "        f\"1. 'persona_prompt': a paragraph describing the writer's persona, expertise, and writing style.\\n\"\n",
    "        f\"2. 'search_queries': a list of at least 3 targeted search queries to research the topic.\\n\"\n",
    "        f\"Be specific, instructive, and ensure the persona matches the requirements.\"\n",
    "    )\n",
    "    response = self.model.generate_content(prompt)\n",
    "    response_text = response.text.strip()\n",
    "    try:\n",
    "        json_str = extract_json_block(response_text)\n",
    "        data = json.loads(json_str)\n",
    "        return PersonaResult(\n",
    "            persona_prompt=data.get(\"persona_prompt\", \"\"),\n",
    "            search_queries=data.get(\"search_queries\", [])\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ JSON parsing error: {e}\")\n",
    "        raise\n",
    "\n",
    "# Attach the method to the class\n",
    "\n",
    "\n",
    "# Assertion to check if method is implemented\n",
    "persona_architect = PersonaArchitect(model)\n",
    "pa = PersonaArchitect(model)\n",
    "'''\n",
    "result_results = pa.generate_persona_and_queries(\n",
    "        \"The History the domestication of chickens\",\n",
    "        \"Professional, accessible tone for general audience\")\n",
    "'''\n",
    "# This will fail until you implement the method properly\n",
    "#try:\n",
    "\n",
    "\n",
    "#    test_result = persona_architect.generate_persona_and_queries(\n",
    "#        \"Artificial Intelligence in Healthcare\",\n",
    "#        \"Professional, accessible tone for general audience\"\n",
    "#    )\n",
    "#    assert isinstance(test_result.persona_prompt, str) and len(test_result.persona_prompt) > 50\n",
    "#    assert isinstance(test_result.search_queries, list) and len(test_result.search_queries) >= 3\n",
    "#    print(\"✅ Exercise 1 completed successfully!\")\n",
    "#    print(f\"📝 Generated persona: {test_result.persona_prompt[:100]}...\")\n",
    "#    print(f\"🔍 Generated {len(test_result.search_queries)} search queries\")\n",
    "#except Exception as e:\n",
    "#    print(f\"❌ Exercise 1 incomplete: {e}\")\n",
    "#    print(\"💡 Hint: Make sure to implement the method and return valid PersonaResult\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "lOq1syoO5e5v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona Prompt:\n",
      "\n",
      "\n",
      "Search Queries:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Example usage of generate_persona_and_queries and returning a valid PersonaResult\n",
    "topic = \"The History of the domestication of chickens\"\n",
    "style_and_background = \"Professional, accessible tone for general audience\"\n",
    "\n",
    "persona_architect = PersonaArchitect(model)\n",
    "persona_result = persona_architect.generate_persona_and_queries(topic, style_and_background)\n",
    "\n",
    "print(\"Persona Prompt:\")\n",
    "print(persona_result.persona_prompt)\n",
    "print(\"\\nSearch Queries:\")\n",
    "print(persona_result.search_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw model response:\n",
      " ```json\n",
      "{\n",
      "  \"persona_prompt\": \"You are a historical science writer and a passionate storyteller specializing in the hidden histories of everyday life, particularly the intersection of human civilization and the natural world. Your writing style is professional, clear, and deeply engaging, designed to make complex topics in anthropology, archaeology, and agricultural history accessible to a curious general audience. You avoid overly academic jargon, instead using vivid descriptions and a strong narrative arc to bring the past to life. For this topic, you will trace the chicken's epic journey from a shy Southeast Asian jungle fowl to a global phenomenon. Your tone is one of wonder and authority, grounding fascinating anecdotes and surprising facts in well-sourced scientific and historical evidence, ultimately aiming to make your readers look at the humble chicken with a newfound sense of awe and appreciation.\",\n",
      "  \"search_queries\": [\n",
      "    \"archaeological and genetic evidence for chicken domestication origin Southeast Asia\",\n",
      "    \"dispersal routes of domesticated chickens from Asia to Europe and the Americas\",\n",
      "    \"cultural and ritualistic roles of early domesticated chickens ancient civilizations\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Parsed JSON keys: ['persona_prompt', 'search_queries']\n"
     ]
    }
   ],
   "source": [
    "# Debug: Print raw model response and parsed JSON keys\n",
    "topic = \"The History of the domestication of chickens\"\n",
    "style_and_background = \"Professional, accessible tone for general audience\"\n",
    "\n",
    "persona_architect = PersonaArchitect(model)\n",
    "response = persona_architect.model.generate_content(\n",
    "    f\"Create a detailed writer persona for the following blog topic and style requirements.\\n\"\n",
    "    f\"Topic: {topic}\\n\"\n",
    "    f\"Style and background: {style_and_background}\\n\"\n",
    "    f\"Return a JSON object with two fields:\\n\"\n",
    "    f\"1. 'persona_prompt': a paragraph describing the writer's persona, expertise, and writing style.\\n\"\n",
    "    f\"2. 'search_queries': a list of at least 3 targeted search queries to research the topic.\\n\"\n",
    "    f\"Be specific, instructive, and ensure the persona matches the requirements.\"\n",
    ")\n",
    "response_text = response.text.strip()\n",
    "print(\"Raw model response:\\n\", response_text)\n",
    "\n",
    "try:\n",
    "    start = response_text.find('{')\n",
    "    end = response_text.rfind('}')\n",
    "    json_str = response_text[start:end+1]\n",
    "    data = json.loads(json_str)\n",
    "    print(\"Parsed JSON keys:\", list(data.keys()))\n",
    "except Exception as e:\n",
    "    print(\"JSON extraction error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XsdiJ9mz5e_l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIhFYhwumv-o"
   },
   "source": [
    "---\n",
    "\n",
    "# 🔍 Exercise 2: Research Analyst Agent\n",
    "\n",
    "## Learning Objectives\n",
    "- Learn to integrate external tools (web search) with LLMs\n",
    "- Practice data synthesis and consolidation\n",
    "- Understand how agents use tools to gather information\n",
    "\n",
    "## Background\n",
    "The **Research Analyst** uses the search queries from Exercise 1 to:\n",
    "1. Perform actual web searches\n",
    "2. Collect and analyze search results\n",
    "3. Synthesize findings into coherent research content\n",
    "\n",
    "This demonstrates how agents use **tools** (the search function) to interact with the world.\n",
    "\n",
    "## Your Task\n",
    "Complete the `ResearchAnalyst` class by implementing the research synthesis logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1069,
     "status": "ok",
     "timestamp": 1756083154171,
     "user": {
      "displayName": "Jacob Zhang",
      "userId": "17792333630785635876"
     },
     "user_tz": 240
    },
    "id": "WkjPtOBimv-p",
    "outputId": "e8ba880d-6b56-4312-b3b1-9b1faf3f9930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 ResearchAnalyst class defined\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PersonaResult' object has no attribute 'queries'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 103\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# The conduct_research method is an instance method, not a static/class method.\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# You need to call it on an instance of ResearchAnalyst, not the class itself.\u001b[39;00m\n\u001b[32m    102\u001b[39m research_analyst = ResearchAnalyst(model, web_searcher)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m result = research_analyst.conduct_research(\u001b[43msearch_queries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mqueries\u001b[49m)\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# This will fail until both Exercise 1 and 2 are implemented\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    107\u001b[39m     \u001b[38;5;66;03m# Test with sample queries\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'PersonaResult' object has no attribute 'queries'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "class ResearchAnalyst:\n",
    "    \"\"\"Agent that conducts web research and synthesizes findings.\"\"\"\n",
    "\n",
    "    def __init__(self, model, web_searcher):\n",
    "        self.model = model\n",
    "        self.web_searcher = web_searcher        \n",
    "\n",
    "    def conduct_research(self, search_queries: List[str]) -> ResearchResult:\n",
    "        \"\"\"Conduct web research and synthesize findings.\n",
    "\n",
    "        Args:\n",
    "            search_queries: List of search queries to execute\n",
    "\n",
    "        Returns:\n",
    "            ResearchResult with synthesized content and source count\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"🔍 Starting web research...\")\n",
    "        all_results = []\n",
    "\n",
    "        # TODO: Execute each search query and collect results\n",
    "        # HINT: Use self.web_searcher.search(query) for each query\n",
    "        # HINT: Combine all results into a single list\n",
    "\n",
    "        for i, query in enumerate(search_queries, 1):\n",
    "            print(f\"   Searching: '{query}'\")\n",
    "            # TODO: Perform the search and add results to all_results\n",
    "            results = []  # Replace with actual search call\n",
    "            all_results.extend(results)\n",
    "\n",
    "            # Be respectful to the search service\n",
    "            if i < len(search_queries):\n",
    "                time.sleep(1)\n",
    "\n",
    "        print(f\"📊 Found {len(all_results)} total search results\")\n",
    "\n",
    "        if not all_results:\n",
    "            return ResearchResult(\n",
    "                content=\"--- RESEARCH START ---\\nNo search results found.\\n--- RESEARCH END ---\",\n",
    "                source_count=0\n",
    "            )\n",
    "\n",
    "        # TODO: Format search results for LLM analysis\n",
    "        # HINT: Create a structured text with all search results\n",
    "        # HINT: Include title, URL, and snippet for each result\n",
    "\n",
    "        search_content = \"\"\n",
    "        for i, result in enumerate(all_results, 1):\n",
    "            # TODO: Format each result\n",
    "            search_content += \"\"  # Add formatted result info\n",
    "\n",
    "        # TODO: Create a prompt to analyze and synthesize the search results\n",
    "        # HINT: Ask the LLM to create a comprehensive research summary\n",
    "        # HINT: Ask for the output to be wrapped in --- RESEARCH START/END --- markers\n",
    "\n",
    "        analysis_prompt = f\"\"\"\n",
    "        # TODO: Write your analysis prompt here\n",
    "        # The prompt should:\n",
    "        # 1. Ask for analysis of the search results\n",
    "        # 2. Request synthesis into coherent research content\n",
    "        # 3. Ask for --- RESEARCH START/END --- markers\n",
    "        # 4. Emphasize accuracy and fact-based synthesis\n",
    "\n",
    "        SEARCH RESULTS TO ANALYZE:\n",
    "        {search_content}\n",
    "\n",
    "        # Your analysis prompt goes here...\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # TODO: Generate content analysis\n",
    "            response = None  # Replace with actual API call\n",
    "            content = \"\"  # Replace with response text\n",
    "\n",
    "            return ResearchResult(\n",
    "                content=content,\n",
    "                source_count=len(all_results)\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error analyzing search results: {e}\")\n",
    "            # Return basic compilation as fallback\n",
    "            basic_content = f\"--- RESEARCH START ---\\nFound {len(all_results)} sources:\\n\"\n",
    "            for result in all_results[:5]:  # Top 5\n",
    "                basic_content += f\"- {result.title}: {result.snippet}\\n\"\n",
    "            basic_content += \"--- RESEARCH END ---\"\n",
    "\n",
    "            return ResearchResult(content=basic_content, source_count=len(all_results))\n",
    "\n",
    "# Test your implementation\n",
    "print(\"🔍 ResearchAnalyst class defined\")\n",
    "# Example usage of conduct_research method\n",
    "topic = \"The History the domestication of chickens\"\n",
    "style_and_background = \"Professional, accessible tone for general audience\"\n",
    "persona_architect = PersonaArchitect(model)\n",
    "search_queries = persona_architect.generate_persona_and_queries(topic, style_and_background)\n",
    "# The conduct_research method is an instance method, not a static/class method.\n",
    "# You need to call it on an instance of ResearchAnalyst, not the class itself.\n",
    "\n",
    "research_analyst = ResearchAnalyst(model, web_searcher)\n",
    "result = research_analyst.conduct_research(search_queries.queries)\n",
    "\n",
    "# This will fail until both Exercise 1 and 2 are implemented\n",
    "try:\n",
    "    # Test with sample queries\n",
    "    test_queries = [\"AI healthcare applications 2024\", \"machine learning medical diagnosis\"]\n",
    "    test_research = research_analyst.conduct_research(test_queries)\n",
    "\n",
    "    assert isinstance(test_research.content, str) and len(test_research.content) > 100\n",
    "    assert \"--- RESEARCH START ---\" in test_research.content\n",
    "    assert \"--- RESEARCH END ---\" in test_research.content\n",
    "    assert test_research.source_count >= 0\n",
    "\n",
    "    print(\"✅ Exercise 2 completed successfully!\")\n",
    "    print(f\"📊 Research content length: {len(test_research.content)} characters\")\n",
    "    print(f\"🔗 Sources found: {test_research.source_count}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Exercise 2 incomplete: {e}\")\n",
    "    print(\"💡 Hint: Make sure to implement web search execution and content synthesis\")\n",
    "    \n",
    "    # The conduct_research method is already implemented above in the ResearchAnalyst class.\n",
    "    # No need to redefine it here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8Mbogs_mv-s"
   },
   "source": [
    "---\n",
    "\n",
    "# ✍️ Exercise 3: Content Synthesizer Agent\n",
    "\n",
    "## Learning Objectives\n",
    "- Learn to combine multiple inputs (persona + research) for content generation\n",
    "- Practice adherence to style guidelines and quality principles\n",
    "- Understand how to handle iterative improvement (revisions)\n",
    "\n",
    "## Background\n",
    "The **Content Synthesizer** is the creative heart of our system. It:\n",
    "1. Takes the persona and research from previous agents\n",
    "2. Writes blog posts that follow the quality principles\n",
    "3. Can revise content based on feedback (iterative improvement)\n",
    "\n",
    "This demonstrates how agents can work with complex, multi-part inputs.\n",
    "\n",
    "## Your Task\n",
    "Complete the `ContentSynthesizer` class by implementing the blog writing logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1756083154199,
     "user": {
      "displayName": "Jacob Zhang",
      "userId": "17792333630785635876"
     },
     "user_tz": 240
    },
    "id": "TVDSX8ummv-t",
    "outputId": "ccb52527-7ac8-48ae-93c1-f73c9d93819d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✍️ ContentSynthesizer class defined\n",
      "⚠️  TODO: Implement the write_blog_post method\n",
      "❌ Exercise 3 incomplete: \n",
      "💡 Hint: Make sure to implement blog writing logic with all required inputs\n"
     ]
    }
   ],
   "source": [
    "class ContentSynthesizer:\n",
    "    \"\"\"Agent that writes blog posts based on persona and research.\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def write_blog_post(self, persona_prompt: str, research_content: str,\n",
    "                       topic: str, style_requirements: str,\n",
    "                       editorial_feedback: Optional[str] = None) -> BlogDraft:\n",
    "        \"\"\"Write a blog post using persona and research.\n",
    "\n",
    "        Args:\n",
    "            persona_prompt: The writer persona to adopt\n",
    "            research_content: Synthesized research content\n",
    "            topic: The blog post topic\n",
    "            style_requirements: Style and background requirements\n",
    "            editorial_feedback: Optional feedback for revision\n",
    "\n",
    "        Returns:\n",
    "            BlogDraft with content and version number\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Create a comprehensive prompt for blog writing\n",
    "        # HINT: Include all the input information in your prompt\n",
    "        # HINT: Reference the QUALITY_PRINCIPLES\n",
    "        # HINT: Handle the optional editorial_feedback for revisions\n",
    "\n",
    "        base_prompt = f\"\"\"\n",
    "        # TODO: Write your blog writing prompt here\n",
    "        # The prompt should:\n",
    "        # 1. Establish the writer persona\n",
    "        # 2. Provide the research content to work with\n",
    "        # 3. Reference the quality principles (use QUALITY_PRINCIPLES variable)\n",
    "        # 4. Specify the topic and style requirements\n",
    "        # 5. Ask for approximately 500 words\n",
    "        # 6. Request Markdown format with title\n",
    "\n",
    "        WRITER PERSONA:\n",
    "        {persona_prompt}\n",
    "\n",
    "        RESEARCH CONTENT:\n",
    "        {research_content}\n",
    "\n",
    "        TOPIC: {topic}\n",
    "\n",
    "        STYLE REQUIREMENTS:\n",
    "        {style_requirements}\n",
    "\n",
    "        QUALITY PRINCIPLES TO FOLLOW:\n",
    "        {QUALITY_PRINCIPLES}\n",
    "\n",
    "        # Your writing instructions go here...\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Handle editorial feedback for revisions\n",
    "        # HINT: If editorial_feedback is provided, add it to the prompt\n",
    "        # HINT: Ask the agent to specifically address the feedback\n",
    "\n",
    "        if editorial_feedback:\n",
    "            base_prompt += f\"\"\"\n",
    "\n",
    "            EDITORIAL FEEDBACK TO ADDRESS:\n",
    "            {editorial_feedback}\n",
    "\n",
    "            # TODO: Add instructions for handling feedback\n",
    "            \"\"\"\n",
    "\n",
    "        try:\n",
    "            # TODO: Generate the blog post content\n",
    "            response = None  # Replace with actual API call\n",
    "            content = \"\"  # Replace with response text\n",
    "\n",
    "            # TODO: Determine version number (1 for new, 2+ for revisions)\n",
    "            version = 1  # Replace with logic based on editorial_feedback\n",
    "\n",
    "            return BlogDraft(content=content, version=version)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in ContentSynthesizer: {e}\")\n",
    "            raise\n",
    "\n",
    "# Test your implementation\n",
    "print(\"✍️ ContentSynthesizer class defined\")\n",
    "print(\"⚠️  TODO: Implement the write_blog_post method\")\n",
    "\n",
    "# Test with sample data\n",
    "content_synthesizer = ContentSynthesizer(model)\n",
    "\n",
    "# This will fail until you implement the method\n",
    "try:\n",
    "    sample_persona = \"Expert technology writer with 10 years of experience in AI and healthcare.\"\n",
    "    sample_research = \"--- RESEARCH START ---\\nAI is transforming healthcare through improved diagnostics and personalized treatment.\\n--- RESEARCH END ---\"\n",
    "\n",
    "    test_draft = content_synthesizer.write_blog_post(\n",
    "        persona_prompt=sample_persona,\n",
    "        research_content=sample_research,\n",
    "        topic=\"AI in Healthcare\",\n",
    "        style_requirements=\"Professional, accessible tone\"\n",
    "    )\n",
    "\n",
    "    assert isinstance(test_draft.content, str) and len(test_draft.content) > 200\n",
    "    assert test_draft.version == 1\n",
    "    assert \"#\" in test_draft.content  # Should have Markdown title\n",
    "\n",
    "    print(\"✅ Exercise 3 completed successfully!\")\n",
    "    print(f\"📝 Blog post length: {len(test_draft.content)} characters\")\n",
    "    print(f\"📄 Version: {test_draft.version}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Exercise 3 incomplete: {e}\")\n",
    "    print(\"💡 Hint: Make sure to implement blog writing logic with all required inputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H7SFl5fmv-v"
   },
   "source": [
    "---\n",
    "\n",
    "# 🔍 Exercise 4: Critic Agent\n",
    "\n",
    "## Learning Objectives\n",
    "- Learn to evaluate content against specific criteria\n",
    "- Practice providing structured feedback\n",
    "- Understand quality assessment in AI systems\n",
    "\n",
    "## Background\n",
    "The **Critic Agent** evaluates blog drafts against our quality principles. It:\n",
    "1. Analyzes the draft for adherence to quality principles (P1-P5)\n",
    "2. Checks factual consistency with research\n",
    "3. Provides structured feedback with specific issues\n",
    "\n",
    "This is the \"evaluator\" part of the **Evaluator-Optimizer** pattern you learned about.\n",
    "\n",
    "## Your Task\n",
    "Complete the `CriticAgent` class by implementing the quality evaluation logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1756083154215,
     "user": {
      "displayName": "Jacob Zhang",
      "userId": "17792333630785635876"
     },
     "user_tz": 240
    },
    "id": "-L7UcJ_imv-w",
    "outputId": "72ae4b3c-e7da-4354-9b94-9bbd038df001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 CriticAgent class defined\n",
      "⚠️  TODO: Implement the evaluate_draft method\n",
      "❌ Exercise 4 incomplete: \n",
      "💡 Hint: Make sure to implement evaluation logic with JSON output parsing\n"
     ]
    }
   ],
   "source": [
    "class CriticAgent:\n",
    "    \"\"\"Agent that evaluates blog drafts against quality principles.\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def evaluate_draft(self, draft_content: str, research_content: str,\n",
    "                      topic: str) -> QualityReview:\n",
    "        \"\"\"Evaluate a blog draft against quality principles.\n",
    "\n",
    "        Args:\n",
    "            draft_content: The blog draft to evaluate\n",
    "            research_content: Original research content for fact-checking\n",
    "            topic: The blog post topic\n",
    "\n",
    "        Returns:\n",
    "            QualityReview with approval status, feedback, and issues\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Create a comprehensive evaluation prompt\n",
    "        # HINT: Ask the LLM to check each quality principle (P1-P5)\n",
    "        # HINT: Request specific feedback about issues found\n",
    "        # HINT: Ask for JSON output with approval status and feedback\n",
    "\n",
    "        evaluation_prompt = f\"\"\"\n",
    "        # TODO: Write your evaluation prompt here\n",
    "        # The prompt should:\n",
    "        # 1. Present the draft to be evaluated\n",
    "        # 2. Provide the research content for fact-checking\n",
    "        # 3. List the quality principles to check against\n",
    "        # 4. Ask for specific analysis of each principle\n",
    "        # 5. Request JSON output with approval and detailed feedback\n",
    "\n",
    "        BLOG DRAFT TO EVALUATE:\n",
    "        {draft_content}\n",
    "\n",
    "        RESEARCH CONTENT FOR FACT-CHECKING:\n",
    "        {research_content}\n",
    "\n",
    "        TOPIC: {topic}\n",
    "\n",
    "        QUALITY PRINCIPLES TO EVALUATE:\n",
    "        {QUALITY_PRINCIPLES}\n",
    "\n",
    "        # Your evaluation instructions go here...\n",
    "        # Remember to ask for JSON format like:\n",
    "        # {{\n",
    "        #   \"is_approved\": true/false,\n",
    "        #   \"feedback\": \"detailed feedback text\",\n",
    "        #   \"issues_found\": [\"list\", \"of\", \"specific\", \"issues\"]\n",
    "        # }}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # TODO: Generate the evaluation\n",
    "            response = None  # Replace with actual API call\n",
    "            response_text = \"\"  # Replace with cleaned response\n",
    "\n",
    "            # TODO: Clean and parse JSON response\n",
    "            # HINT: Remove ```json``` markers if present\n",
    "            # HINT: Use json.loads() to parse\n",
    "\n",
    "            data = {}  # Replace with parsed JSON\n",
    "\n",
    "            return QualityReview(\n",
    "                is_approved=False,  # TODO: Extract from data\n",
    "                feedback=\"\",        # TODO: Extract from data\n",
    "                issues_found=[]     # TODO: Extract from data\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in CriticAgent: {e}\")\n",
    "            # Return safe fallback\n",
    "            return QualityReview(\n",
    "                is_approved=False,\n",
    "                feedback=f\"Error during evaluation: {e}\",\n",
    "                issues_found=[\"Evaluation error occurred\"]\n",
    "            )\n",
    "\n",
    "# Test your implementation\n",
    "print(\"🔍 CriticAgent class defined\")\n",
    "print(\"⚠️  TODO: Implement the evaluate_draft method\")\n",
    "\n",
    "# Test with sample data\n",
    "critic_agent = CriticAgent(model)\n",
    "\n",
    "# This will fail until you implement the method\n",
    "try:\n",
    "    sample_draft = \"# AI in Healthcare\\n\\nArtificial Intelligence is transforming healthcare in many ways...\"\n",
    "    sample_research = \"--- RESEARCH START ---\\nAI applications include medical imaging and drug discovery.\\n--- RESEARCH END ---\"\n",
    "\n",
    "    test_review = critic_agent.evaluate_draft(\n",
    "        draft_content=sample_draft,\n",
    "        research_content=sample_research,\n",
    "        topic=\"AI in Healthcare\"\n",
    "    )\n",
    "\n",
    "    assert isinstance(test_review.is_approved, bool)\n",
    "    assert isinstance(test_review.feedback, str) and len(test_review.feedback) > 10\n",
    "    assert isinstance(test_review.issues_found, list)\n",
    "\n",
    "    print(\"✅ Exercise 4 completed successfully!\")\n",
    "    print(f\"✅ Approved: {test_review.is_approved}\")\n",
    "    print(f\"📝 Feedback length: {len(test_review.feedback)} characters\")\n",
    "    print(f\"⚠️  Issues found: {len(test_review.issues_found)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Exercise 4 incomplete: {e}\")\n",
    "    print(\"💡 Hint: Make sure to implement evaluation logic with JSON output parsing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCQeH6Vxmv-y"
   },
   "source": [
    "---\n",
    "\n",
    "# ✏️ Exercise 5: Editor Agent & Workflow Orchestration\n",
    "\n",
    "## Learning Objectives\n",
    "- Learn to orchestrate multiple agents in a workflow\n",
    "- Implement iterative improvement loops\n",
    "- Understand the complete **Evaluator-Optimizer** pattern\n",
    "\n",
    "## Background\n",
    "The **Editor Agent** manages the iterative improvement process. It:\n",
    "1. Coordinates between the Content Synthesizer and Critic\n",
    "2. Manages the revision loop (up to 3 cycles)\n",
    "3. Makes final approval decisions\n",
    "\n",
    "This demonstrates the complete **Evaluator-Optimizer** workflow from your course!\n",
    "\n",
    "## Your Task\n",
    "Complete the `EditorAgent` class and implement the main workflow orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1756083154240,
     "user": {
      "displayName": "Jacob Zhang",
      "userId": "17792333630785635876"
     },
     "user_tz": 240
    },
    "id": "nSm_gFv5mv-y",
    "outputId": "df450d0a-8d5a-4acf-b613-1859ec5cee8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✏️ EditorAgent and BlogWorkflowOrchestrator classes defined\n",
      "⚠️  TODO: Complete all agent implementations and orchestration logic\n",
      "❌ Exercise 5 incomplete: \n",
      "💡 Hint: Make sure all previous exercises are completed and all agents are initialized\n"
     ]
    }
   ],
   "source": [
    "class EditorAgent:\n",
    "    \"\"\"Agent that manages the iterative improvement workflow.\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def make_editorial_decision(self, quality_review: QualityReview,\n",
    "                               current_cycle: int, max_cycles: int) -> EditorReview:\n",
    "        \"\"\"Make an editorial decision based on critic feedback.\n",
    "\n",
    "        Args:\n",
    "            quality_review: Review from the Critic Agent\n",
    "            current_cycle: Current revision cycle number\n",
    "            max_cycles: Maximum allowed cycles\n",
    "\n",
    "        Returns:\n",
    "            EditorReview with final decision and comments\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Implement editorial decision logic\n",
    "        # HINT: Consider the quality review, current cycle, and max cycles\n",
    "        # HINT: Approve if critic approved, or if max cycles reached\n",
    "        # HINT: Provide constructive feedback for improvements\n",
    "\n",
    "        if quality_review.is_approved:\n",
    "            # TODO: Handle approval case\n",
    "            return EditorReview(\n",
    "                is_approved=True,\n",
    "                comments=\"\"  # TODO: Create approval message\n",
    "            )\n",
    "        elif current_cycle >= max_cycles:\n",
    "            # TODO: Handle max cycles reached\n",
    "            return EditorReview(\n",
    "                is_approved=True,  # Approve despite issues\n",
    "                comments=\"\"  # TODO: Create max cycles message\n",
    "            )\n",
    "        else:\n",
    "            # TODO: Handle revision needed case\n",
    "            return EditorReview(\n",
    "                is_approved=False,\n",
    "                comments=\"\"  # TODO: Format feedback for revision\n",
    "            )\n",
    "\n",
    "class BlogWorkflowOrchestrator:\n",
    "    \"\"\"Main orchestrator that coordinates all agents in the workflow.\"\"\"\n",
    "\n",
    "    def __init__(self, model, web_searcher):\n",
    "        # TODO: Initialize all agents\n",
    "        # HINT: Create instances of all the agent classes you built\n",
    "        self.persona_architect = None    # TODO: Initialize PersonaArchitect\n",
    "        self.research_analyst = None     # TODO: Initialize ResearchAnalyst\n",
    "        self.content_synthesizer = None  # TODO: Initialize ContentSynthesizer\n",
    "        self.critic_agent = None         # TODO: Initialize CriticAgent\n",
    "        self.editor_agent = None         # TODO: Initialize EditorAgent\n",
    "\n",
    "    def generate_blog_post(self, topic: str, style_and_background: str) -> Tuple[str, Path]:\n",
    "        \"\"\"Execute the complete blog generation workflow.\n",
    "\n",
    "        Args:\n",
    "            topic: Blog post topic\n",
    "            style_and_background: Style requirements\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (final_content, final_file_path)\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"🚀 Starting blog generation for: '{topic}'\")\n",
    "\n",
    "        # Initialize file manager\n",
    "        file_manager = FileManager(topic)\n",
    "\n",
    "        try:\n",
    "            # Phase 1: Generate Persona and Queries\n",
    "            print(\"\\n🎭 Phase 1: Generating writer persona and search queries...\")\n",
    "            # TODO: Use PersonaArchitect to generate persona and queries\n",
    "            persona_result = None  # Replace with actual call\n",
    "\n",
    "            print(f\"   Generated persona with {len(persona_result.search_queries)} search queries\")\n",
    "\n",
    "            # Phase 2: Conduct Research\n",
    "            print(\"\\n🔍 Phase 2: Conducting web research...\")\n",
    "            # TODO: Use ResearchAnalyst to conduct research\n",
    "            research_result = None  # Replace with actual call\n",
    "\n",
    "            print(f\"   Research completed with {research_result.source_count} sources\")\n",
    "\n",
    "            # Phase 3: Iterative Content Generation and Review\n",
    "            print(\"\\n✍️ Phase 3: Starting iterative content creation...\")\n",
    "\n",
    "            current_draft = None\n",
    "            max_cycles = 3\n",
    "\n",
    "            for cycle in range(1, max_cycles + 1):\n",
    "                print(f\"\\n   📝 Cycle {cycle}/{max_cycles}\")\n",
    "\n",
    "                # Generate or revise draft\n",
    "                if current_draft is None:\n",
    "                    print(\"      Writing initial draft...\")\n",
    "                    # TODO: Use ContentSynthesizer to write initial draft\n",
    "                    draft = None  # Replace with actual call\n",
    "                else:\n",
    "                    print(\"      Revising draft based on feedback...\")\n",
    "                    # TODO: Use ContentSynthesizer to revise with feedback\n",
    "                    draft = None  # Replace with actual call\n",
    "\n",
    "                current_draft = draft\n",
    "\n",
    "                # Save draft\n",
    "                file_manager.save_file(draft.content, f\"draft_{cycle}.md\")\n",
    "\n",
    "                # Evaluate with Critic\n",
    "                print(\"      Evaluating with Critic Agent...\")\n",
    "                # TODO: Use CriticAgent to evaluate the draft\n",
    "                quality_review = None  # Replace with actual call\n",
    "\n",
    "                # Make editorial decision\n",
    "                print(\"      Making editorial decision...\")\n",
    "                # TODO: Use EditorAgent to make decision\n",
    "                editorial_review = None  # Replace with actual call\n",
    "\n",
    "                # Save review\n",
    "                file_manager.save_file(\n",
    "                    f\"Approved: {editorial_review.is_approved}\\n\\n{editorial_review.comments}\",\n",
    "                    f\"review_{cycle}.md\"\n",
    "                )\n",
    "\n",
    "                print(f\"      Result: {'✅ Approved' if editorial_review.is_approved else '🔄 Needs revision'}\")\n",
    "\n",
    "                if editorial_review.is_approved:\n",
    "                    print(f\"   🎉 Blog post approved after {cycle} cycle(s)!\")\n",
    "                    break\n",
    "\n",
    "                # Store feedback for next revision\n",
    "                last_feedback = editorial_review.comments\n",
    "\n",
    "            # Phase 4: Finalization\n",
    "            print(\"\\n📄 Phase 4: Finalizing blog post...\")\n",
    "            final_path = file_manager.save_file(current_draft.content, \"final_blog.md\")\n",
    "\n",
    "            # Display summary\n",
    "            word_count = len(current_draft.content.split())\n",
    "            print(f\"\\n📊 Generation Summary:\")\n",
    "            print(f\"   📂 Output folder: {file_manager.folder_name}\")\n",
    "            print(f\"   📝 Final word count: {word_count} words\")\n",
    "            print(f\"   🔍 Sources used: {research_result.source_count}\")\n",
    "            print(f\"   🔄 Revision cycles: {cycle}\")\n",
    "\n",
    "            return current_draft.content, final_path\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error during blog generation: {e}\")\n",
    "            raise\n",
    "\n",
    "# Test your implementation\n",
    "print(\"✏️ EditorAgent and BlogWorkflowOrchestrator classes defined\")\n",
    "print(\"⚠️  TODO: Complete all agent implementations and orchestration logic\")\n",
    "\n",
    "# This will fail until all exercises are completed\n",
    "try:\n",
    "    orchestrator = BlogWorkflowOrchestrator(model, web_searcher)\n",
    "\n",
    "    # Verify all agents are initialized\n",
    "    assert orchestrator.persona_architect is not None\n",
    "    assert orchestrator.research_analyst is not None\n",
    "    assert orchestrator.content_synthesizer is not None\n",
    "    assert orchestrator.critic_agent is not None\n",
    "    assert orchestrator.editor_agent is not None\n",
    "\n",
    "    print(\"✅ Exercise 5 setup completed successfully!\")\n",
    "    print(\"🎉 All agents initialized and ready for workflow execution\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Exercise 5 incomplete: {e}\")\n",
    "    print(\"💡 Hint: Make sure all previous exercises are completed and all agents are initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eRKuTwxmv-0"
   },
   "source": [
    "---\n",
    "\n",
    "# 🎯 Final Integration Test\n",
    "\n",
    "Once you've completed all 5 exercises, run this cell to test the complete workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1756083154284,
     "user": {
      "displayName": "Jacob Zhang",
      "userId": "17792333630785635876"
     },
     "user_tz": 240
    },
    "id": "uWRGi9Ptmv-1",
    "outputId": "a86e4655-e129-4cb4-9baa-8958f40f82a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Ready to run integration test...\n",
      "⚠️  Make sure all exercises above are completed first!\n"
     ]
    }
   ],
   "source": [
    "# Final integration test - run the complete workflow\n",
    "def run_complete_workflow():\n",
    "    \"\"\"Run the complete blog generation workflow.\"\"\"\n",
    "\n",
    "    # Sample inputs\n",
    "    topic = \"The Future of Artificial Intelligence in Healthcare\"\n",
    "    style_and_background = \"\"\"\n",
    "    Target audience: General tech-savvy readers interested in healthcare innovation\n",
    "    Tone: Professional but accessible, optimistic yet balanced\n",
    "    Style: Informative with real-world examples, approximately 500 words\n",
    "    Background: Write from the perspective of someone knowledgeable about both AI and healthcare trends\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Initialize orchestrator\n",
    "        orchestrator = BlogWorkflowOrchestrator(model, web_searcher)\n",
    "\n",
    "        # Run complete workflow\n",
    "        final_content, final_path = orchestrator.generate_blog_post(topic, style_and_background)\n",
    "\n",
    "        # Display final result\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"🎉 CAPSTONE PROJECT COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        # Show preview of final blog\n",
    "        preview = final_content[:500] + \"...\" if len(final_content) > 500 else final_content\n",
    "        display(Markdown(f\"### Final Blog Post Preview\\n\\n{preview}\"))\n",
    "\n",
    "        print(f\"\\n📄 Full blog saved to: {final_path}\")\n",
    "        print(\"\\n🏆 Congratulations! You've successfully built a multi-agent system!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Integration test failed: {e}\")\n",
    "        print(\"\\n🔧 Please review and complete all exercises above.\")\n",
    "        return False\n",
    "\n",
    "# Run the test when all exercises are complete\n",
    "print(\"🧪 Ready to run integration test...\")\n",
    "print(\"⚠️  Make sure all exercises above are completed first!\")\n",
    "\n",
    "# Uncomment the next line when you're ready to test:\n",
    "# success = run_complete_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzQB1KRWmv-1"
   },
   "source": [
    "---\n",
    "\n",
    "# 🎓 Capstone Project Summary\n",
    "\n",
    "## What You've Built\n",
    "\n",
    "Congratulations! You've just built a complete **multi-agent system** that demonstrates all the key concepts from your AI Agents course:\n",
    "\n",
    "### 🧠 Agent Fundamentals Applied\n",
    "- **Brain (LLM)**: Each agent uses Gemini Pro 2.5 for reasoning\n",
    "- **Tools**: Web search, file management, content generation\n",
    "- **Result**: 5 specialized agents working together\n",
    "\n",
    "### 🔄 ReAct Framework in Action\n",
    "- **Thought**: Each agent reasons about its specific task\n",
    "- **Action**: Agents use tools (search, generate, evaluate)\n",
    "- **Observation**: Results feed into the next agent or iteration\n",
    "\n",
    "### 🏭 Evaluator-Optimizer Workflow\n",
    "- **Creator**: Content Synthesizer writes drafts\n",
    "- **Evaluator**: Critic Agent reviews against quality principles\n",
    "- **Optimizer**: Editor Agent manages iterative improvement\n",
    "- **Loop**: Up to 3 cycles of continuous improvement\n",
    "\n",
    "## Technical Achievements\n",
    "\n",
    "✅ **Exercise 1**: Persona generation with targeted search queries  \n",
    "✅ **Exercise 2**: Real web search integration and research synthesis  \n",
    "✅ **Exercise 3**: Content generation with persona adherence  \n",
    "✅ **Exercise 4**: Quality evaluation against structured principles  \n",
    "✅ **Exercise 5**: Complete workflow orchestration with iterative improvement\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "The patterns you've learned can be applied to:\n",
    "- **Content Creation**: Automated writing with quality control\n",
    "- **Research & Analysis**: Multi-step investigation workflows\n",
    "- **Code Review**: Automated code evaluation and improvement\n",
    "- **Decision Support**: Multi-agent consultation systems\n",
    "- **Creative Projects**: AI collaboration in design and writing\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you understand multi-agent systems, consider exploring:\n",
    "- **Advanced Workflows**: Try parallel agent execution\n",
    "- **Specialized Tools**: Add more sophisticated tools to your agents\n",
    "- **Domain Expertise**: Create agents for specific industries\n",
    "- **Interactive Systems**: Build agents that can collaborate with humans\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 Course Connection\n",
    "\n",
    "This capstone perfectly demonstrates the progression from your course:\n",
    "\n",
    "1. **Session 1**: Prompt Engineering → Used in every agent interaction\n",
    "2. **Session 2**: RAG → Research integration and knowledge synthesis  \n",
    "3. **Session 3**: AI Agents → Complete multi-agent system with tools\n",
    "\n",
    "You've now experienced the full power of giving AI not just knowledge, but the ability to **act**!\n",
    "\n",
    "---\n",
    "\n",
    "🎉 **Congratulations on completing your AI Agents Capstone Project!** 🎉"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "history_visible": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
